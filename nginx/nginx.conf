http {
    # NGINX configuration uses the service name defined in my docker-compose.yml file
    # This approach relies on Docker to manage load balancing across the replicas.

    # Add a resolver for Docker's internal DNS
    # Docker automatically distributes requests among these IPs in a round-robin fashion.
    # After 10 seconds, NGINX will query the DNS server (127.0.0.11) again to ensure it has the latest IP addresses.
    resolver 127.0.0.11 valid=10s;
    upstream backend {
        server app:5000;
    }

    # Use a map to strip the port from the upstream address
    map $upstream_addr $upstream_ip {
        ~^(?<ip>[0-9.]+):[0-9]+$ $ip;  # Match IP (digits and dots) before the colon and assign to $upstream_ip
        default $upstream_addr;         # Fallback to original $upstream_addr if no match
    }

    # Define a custom log format
    log_format custom_upstream_log '$remote_addr - $remote_user [$time_local] '
                                   '"$request" $status $body_bytes_sent '
                                   '"$http_referer" "$http_user_agent" '
                                   'upstream_addr=$upstream_addr '
                                   'upstream_ip=$upstream_ip '
                                   'request_time=$request_time '
                                   'upstream_response_time=$upstream_response_time';

    # Use the custom log format in the access log
    access_log /var/log/nginx/upstream_requests.log custom_upstream_log;

    server {
        listen 80;

        location / {
            # Dynamically resolve the backend service
            set $backend "app:5000";

            # If the cookie exists, use its value to determine the specific backend server
            if ($cookie_backend_server_id != "") {
                set $backend "$cookie_backend_server_id:5000";
            }

            # Set the sticky session cookie only if it doesn't exist
            if ($cookie_backend_server_id = "") {
                add_header Set-Cookie "backend_server_id=$upstream_ip; Max-Age=300; Path=/; HttpOnly; Secure; SameSite=Lax";
            }

            # Pass important headers to the upstream server
              proxy_set_header Host $host;                     # Forward the original Host header to the backend server
              proxy_set_header X-Real-IP $remote_addr;         # Forward the client's IP to the backend server
              proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; # Forward the IP chain
                                                                           #request comes from a client at 192.168.1.10,
                                                                           #passes through 192.168.1.1
                                                                           # X-Forwarded-For: 192.168.1.10, 192.168.1.1
              proxy_set_header X-Forwarded-Proto $scheme;      # Forward the request scheme (HTTP/HTTPS)

              # Enable HTTP/1.1 for persistent connection support
              proxy_http_version 1.1;         # Use HTTP/1.1 to enable persistent connections, allowing multiple
                                              # requests and responses to use the same connection

              proxy_set_header Connection ""; # Allow persistent connections by clearing the Connection header
                                              # ensures that the connection remains open (persistent) for reuse
                                              # in subsequent requests.

              # Set timeouts for upstream
              proxy_connect_timeout 60s; # Timeout for establishing a connection to the upstream server
              proxy_send_timeout 60s;    # How long NGINX will wait while sending data to the upstream server (backend)
              proxy_read_timeout 60s;    # Timeout for receiving data from the upstream server

              # Pass the request to the dynamically resolved backend
              proxy_pass http://$backend;
        }
    }
}

events {}
